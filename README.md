# Класификатор на Spam Имейли

Уеб приложение на Python и Flask, което използва модел за машинно обучение, имплементиран от нулата, за да класифицира текстови съобщения като 'Spam' (нежелано) или 'Ham' (желано).

## Функционалности

*   **AI Модел, имплементиран от нулата:** Използва се Логистична Регресия, написана изцяло с `Numpy`, без помощта на библиотеки като `Scikit-learn`, `Tensorflow` или `PyTorch`.
*   **Потребителска система:** Пълна система за регистрация, вход и изход на потребители, реализирана с `Flask-Login`.
*   **Потребителски роли:** Разделение на потребителите на "Потребител" и "Администратор" с различни права.
*   **Потребителски профили:** Всеки потребител има собствена страница, където може да редактира данните си.
*   **Интерактивен класификатор:** Уеб интерфейс, където потребителите могат да въведат текст и да получат предсказание от AI модела.
*   **Събиране на данни:** Система за "анкети", чрез която потребителите могат да допринасят с нови примери за обучение.
*   **Пълна уеб структура:** Проектът е изграден с `Flask Blueprints`, използва `Flask-SQLAlchemy` за базата данни, `Flask-Migrate` за миграции, `Flask-WTF` за форми и `Flask-Bootstrap` за дизайн.
*   **Имейл потвърждение:** Функционалност за потвърждение на имейл адрес при регистрация чрез `Flask-Mail`.
*   **Автоматизирани тестове:** Написани са `Unit` тестове за ключови функционалности на приложението.

---

## Детайли за AI Модела

Тази секция отговаря на специфичните изисквания за частта с изкуствен интелект.

### 1. Избор на Алгоритъм (Логистична Регресия)

За решаването на задачата за бинарна класификация ("Spam" или "Ham") беше избран алгоритъмът **Логистична Регресия**.

**Обосновка на избора:**
*   **Подходящ за задачата:** Логистичната регресия е класически и много ефективен алгоритъм именно за проблеми с два възможни изхода. Тя моделира вероятността един обект да принадлежи към даден клас.
*   **Възможност за имплементация от нулата:** Алгоритъмът е математически ясен и може да бъде имплементиран изцяло с `Numpy`, което позволява демонстрация на разбиране на основните принципи. Имплементирани са:
    *   **Сигмоидна функция:** За превръщане на изхода в вероятност.
    *   **Gradient Descent (Метод на градиентно спускане):** За оптимизация на параметрите на модела.
    *   **Binary Cross-Entropy Loss:** Като функция за измерване на грешката по време на обучение.
*   **Интерпретируемост:** Моделът позволява да се види кои думи (признаци) имат най-голяма тежест при взимането на решение.

### 2. Датасет

*   **Източник:** За обучение на модела е използван публичният "Email Spam Classification Dataset" от платформата Kaggle. Той е базиран на популярния "SMS Spam Collection Data Set" от UCI Machine Learning Repository.
*   **Съдържание:** Датасетът съдържа над 5500 текстови съобщения, всяко от които е ръчно етикетирано.
*   **Предварителна обработка:** Преди обучение, данните преминават през следните стъпки на обработка (реализирани в `ai_model/main_preprocessing.py`):
    1.  **Почистване на текста:** Преобразуване на всички букви в малки и премахване на пунктуация и специални символи.
    2.  **Токенизация:** Разделяне на текста на отделни думи (токени).
    3.  **Създаване на речник:** Изграждане на речник от 2000-те най-често срещани думи в целия датасет.
    4.  **Векторизация:** Преобразуване на всяко съобщение в числов вектор.

### 3. Избор на Признаци (Features) - Bag of Words

Моделът използва метода **"Торба с думи" (Bag of Words)** за извличане на признаци от суровия текст.

**Обосновка на избора:**
Този подход превръща всеки текст в числов вектор. Векторът е с дължина, равна на броя думи в речника (в случая 2000). Всяка позиция във вектора отговаря на една дума от речника. Стойността на тази позиция е 1, ако думата присъства в съобщението, и 0, ако не. Този метод е избран, защото:
*   Е фундаментален и лесен за имплементация от нулата.
*   Ефективно улавя кои думи присъстват в текста, което е много силен индикатор за класификация на спам (например наличието на думи като "free", "prize", "winner").

### 4. Оценка на Ефективността

За следене на ефективността на модела по време на обучение и тестване бяха използвани следните метрики, имплементирани ръчно в `ai_model/train_model.py`:

*   **Accuracy (Точност):** Процентът на правилно класифицираните примери от общия брой. Дава обща представа за производителността.
    *   *Формула: (Верни предсказания) / (Общо предсказания)*
*   **Loss (Загуба) - Binary Cross-Entropy:** Измерва колко "греши" моделът. За разлика от точността, тази метрика наказва модела повече, ако е много уверен в грешно предсказание. Целта по време на обучение е тази стойност да намалява.
*   **Error Rate (Процент грешки):** Процентът на грешно класифицираните примери.
    *   *Формула: 1 - Accuracy*

**Постигнат резултат на тестовия сет: ~96-97% точност.**

---

## Инсталация и стартиране

1.  **Клонирайте репозиторито:**
    ```bash
    git clone <your-repo-url>
    cd <project-folder>
    ```

2.  **Създайте и активирайте виртуална среда:**
    ```bash
    python -m venv venv
    # На Windows:
    .\venv\Scripts\activate
    # На macOS/Linux:
    source venv/bin/activate
    ```

3.  **Инсталирайте зависимостите:**
    ```bash
    pip install -r requirements.txt
    ```

4.  **Инициализирайте базата данни:**
    ```bash
    flask db upgrade
    ```

5.  **Стартирайте приложението:**
    ```bash
    python run.py
    ```
Приложението ще бъде достъпно на `http://127.0.0.1:5000`.

## Изпълнение на тестовете

За да изпълните автоматизираните тестове, използвайте следната команда:
```bash
python tests.py
```